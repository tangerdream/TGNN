{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from Dataloader import DataLoader\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from GEvaluator import Evaluator\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "from Mid import GINGraphPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MyNamespace(argparse.Namespace):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batch_size = 2\n",
    "        self.dataset_root = './PTs/dataset_32-3600000_new.pt'\n",
    "        self.device=0\n",
    "        self.drop_ratio=0.1\n",
    "        self.early_stop=20\n",
    "        self.early_stop_open = True\n",
    "        self.emb_dim=256\n",
    "        self.epochs=200\n",
    "        self.graph_pooling='sum'\n",
    "        self.num_layers=3\n",
    "        self.n_head=3\n",
    "        self.num_workers=3\n",
    "        self.num_tasks=1\n",
    "        self.save_test=True\n",
    "        self.task_name='GINGraph'\n",
    "        self.weight_decay=0.5e-05\n",
    "        self.learning_rate=0.0001\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "参数输入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    dataset=torch.load(args.dataset_root)\n",
    "    train_data = dataset[100:900]\n",
    "    valid_data = dataset[0:100]\n",
    "    test_data = dataset[900:999]\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "    test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "    return train_loader,valid_loader,test_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据载入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, criterion_fn):\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "    maxP = 0\n",
    "    minN = 0\n",
    "    avgP = 0\n",
    "    avgN = 0\n",
    "\n",
    "    for step, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "        # print(type(batch))\n",
    "        batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "        pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "        # print(pred.shape)\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        deltayy=pred-batch.y.view(pred.shape)\n",
    "        try:\n",
    "            if maxP<torch.max(deltayy[deltayy>0]):\n",
    "                maxP=max(deltayy[deltayy>0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if minN>torch.min(deltayy[deltayy<0]):\n",
    "                minN=min(deltayy[deltayy<0])\n",
    "        except:\n",
    "            pass\n",
    "        avgP+=torch.mean(deltayy[deltayy>0])\n",
    "        avgN+=torch.mean(deltayy[deltayy<0])\n",
    "        # print(deltayy)\n",
    "        # print(pred.shape,batch.y.shape)\n",
    "        loss = criterion_fn(pred, batch.y.view(pred.shape))  # 计算损失\n",
    "        loss.backward()  # 反向传播，计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        loss_accum += loss.detach().cpu().item()  # 累加损失值\n",
    "\n",
    "    return loss_accum / (step + 1),maxP,minN,avgP / (step + 1),avgN / (step + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算，加速模型运算\n",
    "        for _, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "            # print('test',type(batch))\n",
    "            batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "            pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())  # 将真实值添加到列表中\n",
    "            y_pred.append(pred.detach().cpu())  # 将预测值添加到列表中\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0)  # 拼接真实值列表成一个张量\n",
    "    y_pred = torch.cat(y_pred, dim=0)  # 拼接预测值列表成一个张量\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}  # 构造输入字典\n",
    "    return evaluator.eval(input_dict)[\"mae\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算，加速模型运算\n",
    "        for _, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "            batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "            pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "            y_pred.append(pred.detach().cpu())  # 将预测值添加到列表中\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)  # 拼接预测值列表成一个张量\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def prepartion(args):\n",
    "    save_dir = os.path.join('saves', args.task_name+'_')\n",
    "    if os.path.exists(save_dir):\n",
    "        for idx in range(1000):\n",
    "            if not os.path.exists(save_dir + '=' + str(idx)):\n",
    "                save_dir = save_dir + '=' + str(idx)\n",
    "                break\n",
    "\n",
    "    args.save_dir = save_dir\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    args.device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    args.output_file = open(os.path.join(args.save_dir, 'output'), 'a')\n",
    "    print(args, file=args.output_file, flush=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    prepartion(args)\n",
    "    nn_params = {\n",
    "        'num_layers': args.num_layers,\n",
    "        'emb_dim': args.emb_dim,\n",
    "        'n_head':args.n_head,\n",
    "        'drop_ratio': args.drop_ratio,\n",
    "        'graph_pooling': args.graph_pooling,\n",
    "        'num_tasks':args.num_tasks,\n",
    "        'batchsize':args.batch_size\n",
    "\n",
    "    }\n",
    "\n",
    "    # automatic dataloading and splitting\n",
    "    train_loader,valid_loader,test_loader=load_data(args)\n",
    "\n",
    "    # automatic evaluator. takes dataset name as input\n",
    "    evaluator = Evaluator()\n",
    "    criterion_fn = torch.nn.MSELoss()\n",
    "\n",
    "    device = args.device\n",
    "\n",
    "    model = GINGraphPooling(**nn_params).to(device)\n",
    "\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'#Params: {num_params}', file=args.output_file, flush=True)\n",
    "    print(model, file=args.output_file, flush=True)\n",
    "\n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.25)\n",
    "\n",
    "\n",
    "    writer = SummaryWriter(log_dir=args.save_dir)\n",
    "\n",
    "    not_improved = 0\n",
    "    best_valid_mae = 9999\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        print('epoch:', epoch,time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) )\n",
    "\n",
    "        print(\"=====Epoch {}\".format(epoch), file=args.output_file, flush=True)\n",
    "        print('Training...', file=args.output_file, flush=True)\n",
    "        train_mae,maxP,minN,avgP,avgN = train(model, device, train_loader, optimizer, criterion_fn)\n",
    "        print(train_mae,maxP,minN,avgP,avgN)\n",
    "        print('Evaluating...', file=args.output_file, flush=True)\n",
    "        valid_mae = eval(model, device, valid_loader, evaluator)\n",
    "\n",
    "        print({'Train': train_mae, 'Validation': valid_mae}, file=args.output_file, flush=True)\n",
    "\n",
    "        writer.add_scalar('valid/mae', valid_mae, epoch)\n",
    "        writer.add_scalar('train/mae', train_mae, epoch)\n",
    "        writer.add_scalar('train/maxP', maxP, epoch)\n",
    "        writer.add_scalar('train/minN', minN, epoch)\n",
    "        writer.add_scalar('train/avgP', avgP, epoch)\n",
    "        writer.add_scalar('train/avgN', avgN, epoch)\n",
    "\n",
    "\n",
    "\n",
    "        if valid_mae < best_valid_mae:\n",
    "            best_valid_mae = valid_mae\n",
    "            if args.save_test:\n",
    "                print('Saving checkpoint...', file=args.output_file, flush=True)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(), 'best_val_mae': best_valid_mae, 'num_params': num_params\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(args.save_dir, 'checkpoint.pt'))\n",
    "                print('Predicting on test data...', file=args.output_file, flush=True)\n",
    "                y_pred = test(model, device, test_loader)\n",
    "                print('Saving test submission file...', file=args.output_file, flush=True)\n",
    "                evaluator.save_test_submission({'y_pred': y_pred}, args.save_dir)\n",
    "\n",
    "            not_improved = 0\n",
    "        else:\n",
    "            not_improved += 1\n",
    "            if not_improved == args.early_stop:\n",
    "                print(f\"Have not improved for {not_improved} epoches.\", file=args.output_file, flush=True)\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f'Best validation MAE so far: {best_valid_mae}', file=args.output_file, flush=True)\n",
    "\n",
    "    # writer.add_graph(model,train_loader)\n",
    "    writer.close()\n",
    "    args.output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 2023-07-16 01:07:12\n",
      "14.86416460102424 tensor(16.7342, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-14.0750, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 2 2023-07-16 01:07:39\n",
      "5.595694611278304 tensor(9.0663, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-7.9893, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 3 2023-07-16 01:08:05\n",
      "5.194968809681595 tensor(5.6372, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-7.5703, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 4 2023-07-16 01:08:24\n",
      "3.488265853847843 tensor(6.3754, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-6.1326, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 5 2023-07-16 01:08:49\n",
      "3.2734606939239894 tensor(6.3846, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-7.4238, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 6 2023-07-16 01:09:08\n",
      "2.056088979979977 tensor(4.4093, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-4.7098, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 7 2023-07-16 01:09:27\n",
      "1.8021140212111642 tensor(4.4317, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.7465, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 8 2023-07-16 01:09:47\n",
      "1.538225298098987 tensor(3.9541, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.6398, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 9 2023-07-16 01:10:12\n",
      "1.1887959544274782 tensor(3.1186, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.3723, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 10 2023-07-16 01:10:31\n",
      "1.1354550421555176 tensor(3.4902, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.4094, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 11 2023-07-16 01:10:56\n",
      "1.1075738317810464 tensor(5.3173, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.7959, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 12 2023-07-16 01:11:15\n",
      "0.9688947742794699 tensor(3.2683, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.0404, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 13 2023-07-16 01:11:34\n",
      "0.9800169562378869 tensor(3.3234, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.5933, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 14 2023-07-16 01:11:53\n",
      "1.027573598705203 tensor(2.8595, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.5256, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 15 2023-07-16 01:12:12\n",
      "0.9232133490956039 tensor(3.2939, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.2734, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 16 2023-07-16 01:12:31\n",
      "0.9399641424292349 tensor(3.6293, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.3305, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 17 2023-07-16 01:12:49\n",
      "0.9987731183914001 tensor(4.2187, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.2509, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 18 2023-07-16 01:13:15\n",
      "0.9063196541531943 tensor(3.0359, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.4403, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 19 2023-07-16 01:13:34\n",
      "0.8878890900750411 tensor(3.9012, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.2416, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 20 2023-07-16 01:13:53\n",
      "0.9152703045017552 tensor(2.9445, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.4481, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 21 2023-07-16 01:14:12\n",
      "0.9100861891816021 tensor(3.3921, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.3532, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 22 2023-07-16 01:14:31\n",
      "0.9333094981934118 tensor(2.9838, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-4.2044, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 23 2023-07-16 01:14:49\n",
      "0.8843646191473817 tensor(3.0636, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.2720, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 24 2023-07-16 01:15:15\n",
      "0.854235534873751 tensor(3.6657, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.2955, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 25 2023-07-16 01:15:34\n",
      "0.785655655375449 tensor(3.6150, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.1186, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 26 2023-07-16 01:15:52\n",
      "0.7746538212546148 tensor(3.6122, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.4974, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 27 2023-07-16 01:16:11\n",
      "0.6982594044849975 tensor(2.8140, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.6156, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 28 2023-07-16 01:16:29\n",
      "0.7319170989649137 tensor(3.2890, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.4316, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 29 2023-07-16 01:16:55\n",
      "0.6936576124280691 tensor(3.5328, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.0636, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 30 2023-07-16 01:17:14\n",
      "0.7061235145961109 tensor(2.7063, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-3.0859, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 31 2023-07-16 01:17:33\n",
      "0.5557864550691738 tensor(2.7259, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.2869, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 32 2023-07-16 01:17:52\n",
      "0.5204102429541672 tensor(2.3083, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.2755, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 33 2023-07-16 01:18:12\n",
      "0.5011802477900915 tensor(2.3638, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.5453, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 34 2023-07-16 01:18:31\n",
      "0.5087351240563476 tensor(2.3592, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9282, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 35 2023-07-16 01:18:50\n",
      "0.4424090904608602 tensor(2.3779, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9268, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 36 2023-07-16 01:19:09\n",
      "0.43585331686073914 tensor(2.2947, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8817, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 37 2023-07-16 01:19:28\n",
      "0.4469149118650239 tensor(2.0005, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9087, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 38 2023-07-16 01:19:47\n",
      "0.4231601390748983 tensor(2.4671, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.1420, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 39 2023-07-16 01:20:06\n",
      "0.4124471487622941 tensor(2.1796, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.0920, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 40 2023-07-16 01:20:25\n",
      "0.39621118579896575 tensor(1.7192, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9815, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 41 2023-07-16 01:20:51\n",
      "0.3704769286944065 tensor(2.7868, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.0345, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 42 2023-07-16 01:21:10\n",
      "0.38354015129760227 tensor(2.2939, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.3156, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 43 2023-07-16 01:21:41\n",
      "0.38012904757022625 tensor(2.1608, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.0309, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 44 2023-07-16 01:22:23\n",
      "0.3589857504353586 tensor(2.0139, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9150, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 45 2023-07-16 01:22:50\n",
      "0.33075250697576847 tensor(1.9050, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9026, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 46 2023-07-16 01:23:22\n",
      "0.318174714682973 tensor(1.9885, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.2176, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 47 2023-07-16 01:23:47\n",
      "0.3095311574345396 tensor(1.8486, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6727, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 48 2023-07-16 01:24:08\n",
      "0.30995967135155295 tensor(1.8274, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.0887, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 49 2023-07-16 01:24:28\n",
      "0.29813844647811494 tensor(2.3886, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9946, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 50 2023-07-16 01:24:48\n",
      "0.31118557510890243 tensor(1.9066, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.1808, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 51 2023-07-16 01:25:08\n",
      "0.30391515133000213 tensor(1.8854, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8793, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 52 2023-07-16 01:25:33\n",
      "0.2752235621883301 tensor(1.5808, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8951, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 53 2023-07-16 01:25:52\n",
      "0.28074222823473066 tensor(2.0124, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-2.2036, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 54 2023-07-16 01:26:17\n",
      "0.2624657371781541 tensor(1.5978, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8411, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 55 2023-07-16 01:26:37\n",
      "0.2474750304438203 tensor(1.8674, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.9860, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 56 2023-07-16 01:26:57\n",
      "0.23474330769880908 tensor(1.5735, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8040, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 57 2023-07-16 01:27:17\n",
      "0.2615221910845139 tensor(1.5920, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6773, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 58 2023-07-16 01:27:43\n",
      "0.23912465780216735 tensor(1.9318, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5034, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 59 2023-07-16 01:28:02\n",
      "0.24310063198339776 tensor(1.9655, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8068, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 60 2023-07-16 01:28:20\n",
      "0.2298374893165419 tensor(1.9475, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5806, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 61 2023-07-16 01:28:39\n",
      "0.1807319360721158 tensor(1.4265, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5556, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 62 2023-07-16 01:28:58\n",
      "0.17386051558767973 tensor(1.3450, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4512, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 63 2023-07-16 01:29:25\n",
      "0.18075068946873216 tensor(1.7195, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4126, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 64 2023-07-16 01:29:45\n",
      "0.18431282579498656 tensor(1.4954, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6666, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 65 2023-07-16 01:30:13\n",
      "0.16713432040680345 tensor(1.7454, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.8149, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 66 2023-07-16 01:30:33\n",
      "0.1579945045497152 tensor(1.5574, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5001, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 67 2023-07-16 01:30:53\n",
      "0.15705883226910372 tensor(1.5070, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6688, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 68 2023-07-16 01:31:12\n",
      "0.15488891855218753 tensor(1.1881, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5441, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 69 2023-07-16 01:31:31\n",
      "0.15887891252808914 tensor(1.5267, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.7144, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 70 2023-07-16 01:31:50\n",
      "0.1497864584346098 tensor(1.3600, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4873, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 71 2023-07-16 01:32:12\n",
      "0.14737210095699993 tensor(1.2366, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.7458, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 72 2023-07-16 01:32:33\n",
      "0.14710365873637785 tensor(1.2966, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5894, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 73 2023-07-16 01:32:54\n",
      "0.1443567742221205 tensor(1.2675, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5188, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 74 2023-07-16 01:33:15\n",
      "0.15781996691875974 tensor(1.8905, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4509, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 75 2023-07-16 01:33:36\n",
      "0.14215935098329283 tensor(1.2521, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5826, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 76 2023-07-16 01:33:57\n",
      "0.15007613606216183 tensor(1.4187, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6109, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 77 2023-07-16 01:34:16\n",
      "0.13798765134983115 tensor(1.2222, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2945, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 78 2023-07-16 01:34:36\n",
      "0.1380236392464576 tensor(1.2636, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3203, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 79 2023-07-16 01:34:56\n",
      "0.1416051659955633 tensor(1.1903, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.7864, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 80 2023-07-16 01:35:22\n",
      "0.13076370226379366 tensor(1.4066, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3335, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 81 2023-07-16 01:35:41\n",
      "0.13138284548869705 tensor(1.1035, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.6830, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 82 2023-07-16 01:36:00\n",
      "0.13292320655033107 tensor(1.1867, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4306, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 83 2023-07-16 01:36:20\n",
      "0.13407041340338766 tensor(1.2552, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3522, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 84 2023-07-16 01:36:39\n",
      "0.13148089952388545 tensor(1.4479, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4378, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 85 2023-07-16 01:36:59\n",
      "0.13395556157789543 tensor(1.1370, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3527, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 86 2023-07-16 01:37:18\n",
      "0.12494593914425423 tensor(1.2254, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3869, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 87 2023-07-16 01:37:37\n",
      "0.12844776848884065 tensor(1.3695, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3517, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 88 2023-07-16 01:37:57\n",
      "0.12265425716534083 tensor(1.2859, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3926, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 89 2023-07-16 01:38:16\n",
      "0.13071532098540048 tensor(1.1884, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5622, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 90 2023-07-16 01:38:42\n",
      "0.12283525174429996 tensor(1.1909, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3791, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 91 2023-07-16 01:39:02\n",
      "0.10711630906374012 tensor(1.1416, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1032, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 92 2023-07-16 01:39:22\n",
      "0.12492481133405818 tensor(1.2602, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1649, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 93 2023-07-16 01:39:41\n",
      "0.10691949019492313 tensor(1.2179, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1236, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 94 2023-07-16 01:40:00\n",
      "0.10654981308780406 tensor(1.1036, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5774, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 95 2023-07-16 01:40:19\n",
      "0.10258224881741626 tensor(1.0609, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.0938, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 96 2023-07-16 01:40:39\n",
      "0.1057355495318916 tensor(1.0984, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3289, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 97 2023-07-16 01:40:58\n",
      "0.11090729970261236 tensor(0.9523, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.3674, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 98 2023-07-16 01:41:17\n",
      "0.11254286607450922 tensor(1.3113, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2887, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 99 2023-07-16 01:41:36\n",
      "0.1129787817747092 tensor(1.1363, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2964, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 100 2023-07-16 01:42:02\n",
      "0.10013833795390382 tensor(1.1041, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1924, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 101 2023-07-16 01:42:20\n",
      "0.10409363839346042 tensor(1.4345, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5299, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 102 2023-07-16 01:42:40\n",
      "0.10891018702735891 tensor(1.0688, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4878, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 103 2023-07-16 01:43:00\n",
      "0.10340004724419487 tensor(1.0395, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.5000, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 104 2023-07-16 01:43:19\n",
      "0.1044608516183871 tensor(1.1861, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2475, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 105 2023-07-16 01:43:38\n",
      "0.11002991858913447 tensor(1.2094, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.0320, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 106 2023-07-16 01:43:56\n",
      "0.10806034055145573 tensor(1.0948, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1594, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 107 2023-07-16 01:44:15\n",
      "0.09450096833815223 tensor(1.1567, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.0840, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 108 2023-07-16 01:44:33\n",
      "0.09752491527528036 tensor(0.9892, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4225, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 109 2023-07-16 01:44:52\n",
      "0.10987381035629369 tensor(1.6328, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2120, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 110 2023-07-16 01:45:11\n",
      "0.10326659856182233 tensor(1.1171, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.1530, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 111 2023-07-16 01:45:30\n",
      "0.1097102331982751 tensor(1.0975, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.4268, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 112 2023-07-16 01:45:49\n",
      "0.10963540533011837 tensor(1.3043, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-1.2308, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# args=p_args()\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     args\u001B[38;5;241m=\u001B[39mMyNamespace()\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinish\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[8], line 70\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m     68\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(checkpoint, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(args\u001B[38;5;241m.\u001B[39msave_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoint.pt\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicting on test data...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_file, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 70\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSaving test submission file...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_file, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     72\u001B[0m evaluator\u001B[38;5;241m.\u001B[39msave_test_submission({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m'\u001B[39m: y_pred}, args\u001B[38;5;241m.\u001B[39msave_dir)\n",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(model, device, loader)\u001B[0m\n\u001B[0;32m      3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():  \u001B[38;5;66;03m# 禁用梯度计算，加速模型运算\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m:  \u001B[38;5;66;03m# 枚举所有批次的数据\u001B[39;00m\n\u001B[0;32m      7\u001B[0m         batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# 将数据移动到指定的设备\u001B[39;00m\n\u001B[0;32m      8\u001B[0m         pred \u001B[38;5;241m=\u001B[39m model(batch)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, )  \u001B[38;5;66;03m# 前向传播，计算预测值\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # args=p_args()\n",
    "    args=MyNamespace()\n",
    "    main(args)\n",
    "    print('finish')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
