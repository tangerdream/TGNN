{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "import torch\n",
    "from GEvaluator import Evaluator\n",
    "from tqdm import tqdm\n",
    "from Mid import GINGraphPooling\n",
    "print('torch version:',torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "参数输入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#参数输入\n",
    "class MyNamespace(argparse.Namespace):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batch_size = 20\n",
    "        self.device=0\n",
    "        self.drop_ratio=0.1\n",
    "        self.early_stop=30\n",
    "        self.early_stop_open = True\n",
    "        self.emb_dim=256\n",
    "        self.epochs=200\n",
    "        self.graph_pooling='sum'\n",
    "        self.num_layers=3\n",
    "        self.n_head=3\n",
    "        self.num_workers=5\n",
    "        self.num_tasks=1\n",
    "        self.save_test=True\n",
    "        self.task_name='test'\n",
    "        self.weight_decay=0.5e-05\n",
    "        self.learning_rate=0.0001\n",
    "        self.root='./Dataset_Producer/Smiles_process/data.csv.gz'\n",
    "        self.data_type='smiles'\n",
    "        # self.producer='SmilesProcess'\n",
    "        # self.y_name = 'homolumogap'\n",
    "        # self.dataset_use_pt=True\n",
    "        self.dataset_pt = 'PTs/my_dataset.pt_0'\n",
    "        self.dataset_split=[0.8,0.19,0.01]\n",
    "        self.begin=0\n",
    "        self.evaluate_epoch=3\n",
    "        self.continue_train=False\n",
    "        self.checkpoint_path='./saves/GINGraph-con-v100_/checkpoint.pt'\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据载入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#数据载入\n",
    "def load_data(args):\n",
    "\n",
    "    if os.path.isdir(args.dataset_pt):\n",
    "        print('data loading in dir:',args.dataset_pt)\n",
    "        dataset=[]\n",
    "        for filename in tqdm(os.listdir(args.dataset_pt)):\n",
    "            dataset.extend(torch.load(os.path.join(args.dataset_pt,filename)))\n",
    "            # print(len(dataset))\n",
    "    else:\n",
    "        print('data loading in .pt:', args.dataset_pt)\n",
    "        dataset=torch.load(args.dataset_pt)\n",
    "    # else:\n",
    "    #     print('Dataset: data loading from',args.begin,'to',args.begin+args.dataset_length)\n",
    "    #     dataset = eval(args.producer)(args.root,args.y_name,save=False,begin=args.begin,length=args.dataset_length)\n",
    "\n",
    "    length=len(dataset)\n",
    "    train_idx=round(length*args.dataset_split[0])\n",
    "    valid_idx=round(length*(args.dataset_split[0]+args.dataset_split[1]))\n",
    "    test_idx = round(length * (args.dataset_split[0]+args.dataset_split[1] + args.dataset_split[2]))\n",
    "\n",
    "    train_data=dataset[0:train_idx]\n",
    "    valid_data=dataset[train_idx:valid_idx]\n",
    "    test_data=dataset[valid_idx:test_idx]\n",
    "\n",
    "    print('train data:',len(train_data),'valid data:',len(valid_data))\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "    test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "    return train_loader,valid_loader,test_loader\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#trainer\n",
    "def train(model, device, loader, optimizer, criterion_fn,epoch,epochs):\n",
    "    print('on training:')\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "    maxP = 0\n",
    "    minN = 0\n",
    "    avgP = 0\n",
    "    avgN = 0\n",
    "\n",
    "    pbar=tqdm(total = len(loader), desc=f'Epoch {epoch}/{epochs}', unit='it')\n",
    "    for step, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "        # print(step)\n",
    "        # print(type(batch))\n",
    "        batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "        # print(batch.x)\n",
    "        pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "        try:\n",
    "            assert not torch.any(torch.isnan(pred))\n",
    "        except:\n",
    "            print(batch.new_pos)\n",
    "            break\n",
    "        # print(pred.shape)\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        deltayy=pred-batch.y.view(pred.shape)\n",
    "        try:\n",
    "            if maxP<torch.max(deltayy[deltayy>0]):\n",
    "                maxP=max(deltayy[deltayy>0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if minN>torch.min(deltayy[deltayy<0]):\n",
    "                minN=min(deltayy[deltayy<0])\n",
    "        except:\n",
    "            pass\n",
    "        avgP+=torch.mean(deltayy[deltayy>0])\n",
    "        avgN+=torch.mean(deltayy[deltayy<0])\n",
    "        # print(deltayy)\n",
    "        # print(pred.shape,batch.y.shape)\n",
    "        loss = criterion_fn(pred, batch.y.view(pred.shape))  # 计算损失\n",
    "        assert not torch.any(torch.isnan(loss))\n",
    "\n",
    "        pbar.set_postfix({'loss' : '{0:1.5f}'.format(loss)}) #在进度条后显示当前batch的损失\n",
    "        pbar.update(1) #更当前进度，1表示完成了一个batch的训练\n",
    "\n",
    "        loss.backward()  # 反向传播，计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        loss_accum += loss.detach().cpu().item()  # 累加损失值\n",
    "\n",
    "    return loss_accum / (step + 1),maxP,minN,avgP / (step + 1),avgN / (step + 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#evaluator\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pbar = tqdm(total=len(loader), desc=f'Evaluating:', unit='it')\n",
    "    with torch.no_grad():  # 禁用梯度计算，加速模型运算\n",
    "        for _, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "            # print('test',type(batch))\n",
    "            batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "            pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "            try:\n",
    "                assert not torch.any(torch.isnan(pred))\n",
    "                y_true.append(batch.y.view(pred.shape).detach().cpu())  # 将真实值添加到列表中\n",
    "                y_pred.append(pred.detach().cpu())  # 将预测值添加到列表中\n",
    "            except:\n",
    "                print(batch.new_pos,batch.x)\n",
    "                pass\n",
    "            pbar.update(1)  # 更当前进度，1表示完成了一个batch的训练\n",
    "    print('Evaluate finish')\n",
    "\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0)  # 拼接真实值列表成一个张量\n",
    "    y_pred = torch.cat(y_pred, dim=0)  # 拼接预测值列表成一个张量\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}  # 构造输入字典\n",
    "    return evaluator.eval(input_dict)[\"mae\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#tester\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    pbar = tqdm(total=len(loader), desc=f'Testing:', unit='it')\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算，加速模型运算\n",
    "        for _, batch in enumerate(loader):  # 枚举所有批次的数据\n",
    "            batch = batch.to(device)  # 将数据移动到指定的设备\n",
    "            pred = model(batch).view(-1, )  # 前向传播，计算预测值\n",
    "            # print(pred)\n",
    "            try:\n",
    "                assert not torch.any(torch.isnan(pred))\n",
    "                y_pred.append(pred.detach().cpu())  # 将预测值添加到列表中\n",
    "            except:\n",
    "                print(batch.new_pos,batch.x)\n",
    "                pass\n",
    "            pbar.update(1)\n",
    "\n",
    "    # print('y_pred:',y_pred)\n",
    "    y_pred = torch.cat(y_pred, dim=0)  # 拼接预测值列表成一个张量\n",
    "    print('Test finish')\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#log_save\n",
    "def prepartion(args):\n",
    "    save_dir = os.path.join('saves', args.task_name+'_')\n",
    "    if os.path.exists(save_dir):\n",
    "        for idx in range(1000):\n",
    "            if not os.path.exists(save_dir + '=' + str(idx)):\n",
    "                save_dir = save_dir + '=' + str(idx)\n",
    "                break\n",
    "\n",
    "    args.save_dir = save_dir\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    args.device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    args.output_file = open(os.path.join(args.save_dir, 'output'), 'a')\n",
    "    print(args, file=args.output_file, flush=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#continue_train\n",
    "def continue_train(args,model,optimizer):\n",
    "    print('loading modle from',args.checkpoint_path)\n",
    "    checkpoint = torch.load(args.checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print('Load finish')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    prepartion(args)\n",
    "    nn_params = {\n",
    "        'num_layers': args.num_layers,\n",
    "        'emb_dim': args.emb_dim,\n",
    "        'n_head':args.n_head,\n",
    "        'drop_ratio': args.drop_ratio,\n",
    "        'graph_pooling': args.graph_pooling,\n",
    "        'num_tasks':args.num_tasks,\n",
    "        'data_type':args.data_type\n",
    "\n",
    "    }\n",
    "\n",
    "    # automatic dataloading and splitting\n",
    "    train_loader,valid_loader,test_loader=load_data(args)\n",
    "\n",
    "    # automatic evaluator. takes dataset name as input\n",
    "    evaluator = Evaluator()\n",
    "    criterion_fn = torch.nn.MSELoss()\n",
    "\n",
    "    device = args.device\n",
    "\n",
    "    model = GINGraphPooling(**nn_params).to(device)\n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "    if args.continue_train:\n",
    "        continue_train(args,model,optimizer)\n",
    "\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print('train data:', len(train_loader), 'valid data:', len(valid_loader), file=args.output_file, flush=True)\n",
    "    print(f'#Params: {num_params}', file=args.output_file, flush=True)\n",
    "    print(model, file=args.output_file, flush=True)\n",
    "\n",
    "\n",
    "    writer = SummaryWriter(log_dir=args.save_dir)\n",
    "\n",
    "    not_improved = 0\n",
    "    evaluate=1\n",
    "    best_valid_mae = 9999\n",
    "    valid_mae=10000\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        print('=====epoch:', epoch,time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) )\n",
    "\n",
    "        print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\"=====Epoch {}\".format(epoch), file=args.output_file, flush=True)\n",
    "        print('Training...', file=args.output_file, flush=True)\n",
    "        train_mae,maxP,minN,avgP,avgN = train(model, device, train_loader, optimizer, criterion_fn,epoch,args.epochs)\n",
    "        print(train_mae,maxP,minN,avgP,avgN)\n",
    "        print('Evaluating...', file=args.output_file, flush=True)\n",
    "        if epoch==evaluate:\n",
    "            valid_mae = eval(model, device, valid_loader, evaluator)\n",
    "            evaluate += args.evaluate_epoch\n",
    "\n",
    "        print({'Train': train_mae, 'Validation': valid_mae}, file=args.output_file, flush=True)\n",
    "\n",
    "        writer.add_scalar('valid/mae', valid_mae, epoch)\n",
    "        writer.add_scalar('train/mae', train_mae, epoch)\n",
    "        writer.add_scalar('train/maxP', maxP, epoch)\n",
    "        writer.add_scalar('train/minN', minN, epoch)\n",
    "        writer.add_scalar('train/avgP', avgP, epoch)\n",
    "        writer.add_scalar('train/avgN', avgN, epoch)\n",
    "\n",
    "\n",
    "\n",
    "        if valid_mae < best_valid_mae:\n",
    "            print('valid_mae:',valid_mae,'Saving checkpoint...')\n",
    "            best_valid_mae = valid_mae\n",
    "            if args.save_test:\n",
    "                print('Saving checkpoint...', file=args.output_file, flush=True)\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(), 'best_val_mae': best_valid_mae, 'num_params': num_params\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(args.save_dir, 'checkpoint.pt'))\n",
    "                print('Predicting on test data...', file=args.output_file, flush=True)\n",
    "                y_pred = test(model, device, test_loader)\n",
    "                print('Saving test submission file...', file=args.output_file, flush=True)\n",
    "                evaluator.save_test_submission({'y_pred': y_pred}, args.save_dir)\n",
    "\n",
    "            not_improved = 0\n",
    "        else:\n",
    "            not_improved += 1\n",
    "            if not_improved == args.early_stop:\n",
    "                print(f\"Have not improved for {not_improved} epoches.\", file=args.output_file, flush=True)\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f'Best validation MAE so far: {best_valid_mae}', file=args.output_file, flush=True)\n",
    "\n",
    "    # writer.add_graph(model,train_loader)\n",
    "    writer.close()\n",
    "    args.output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading in .pt: PTs/my_dataset.pt_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 0/81 [10:30<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 801 valid data: 190\n",
      "=====epoch: 1 2023-07-30 00:35:14\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 41/41 [00:11<00:00,  3.43it/s, loss=6.19097] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.790309144229425 tensor(19.5846, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-23.3893, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(3.8861, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate finish\n",
      "valid_mae: 5.02234411239624 Saving checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finish\n",
      "=====epoch: 2 2023-07-30 00:35:38\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 41/41 [00:11<00:00,  3.53it/s, loss=4.62124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.627864325918803 tensor(9.1434, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-8.2444, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-2.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 3 2023-07-30 00:35:50\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 41/41 [00:11<00:00,  3.67it/s, loss=20.59150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.823433817886725 tensor(7.3651, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-7.0134, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 4 2023-07-30 00:36:01\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 41/41 [00:11<00:00,  3.60it/s, loss=0.00060] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.871299137413876 tensor(9.9634, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-8.5888, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.9094, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate finish\n",
      "valid_mae: 1.4577231407165527 Saving checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finish\n",
      "=====epoch: 5 2023-07-30 00:36:25\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 41/41 [00:11<00:00,  3.65it/s, loss=66.43970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.885733482314319 tensor(6.8525, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-8.1511, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.7479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 6 2023-07-30 00:36:37\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 41/41 [00:11<00:00,  3.70it/s, loss=1.03358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.403848371854642 tensor(7.5867, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-6.0387, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(1.6077, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 7 2023-07-30 00:36:48\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 41/41 [00:11<00:00,  3.57it/s, loss=0.00007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.348145340095315 tensor(6.5908, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-6.0656, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.6348, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate finish\n",
      "valid_mae: 1.265364408493042 Saving checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finish\n",
      "=====epoch: 8 2023-07-30 00:37:14\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 41/41 [00:11<00:00,  3.57it/s, loss=3.93396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.168999936522507 tensor(6.1509, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-6.1446, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 9 2023-07-30 00:37:25\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 41/41 [00:11<00:00,  3.56it/s, loss=7.57969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57829653926012 tensor(6.2248, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-6.6265, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>) tensor(-1.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 10 2023-07-30 00:37:37\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 41/41 [00:11<00:00,  3.56it/s, loss=6.17002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6694861127109064 tensor(6.2300, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-5.2536, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(1.5400, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate finish\n",
      "=====epoch: 11 2023-07-30 00:37:58\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 41/41 [00:11<00:00,  3.67it/s, loss=1.21829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6132957499201703 tensor(6.1594, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(-5.7773, device='cuda:0', grad_fn=<UnbindBackward0>) tensor(1.5211, device='cuda:0', grad_fn=<DivBackward0>) tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "=====epoch: 12 2023-07-30 00:38:09\n",
      "on training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# args=p_args()\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     args\u001B[38;5;241m=\u001B[39mMyNamespace()\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinish\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[29], line 48\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m, time\u001B[38;5;241m.\u001B[39mlocaltime()),\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=====Epoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch), file\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_file, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_file, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 48\u001B[0m train_mae,maxP,minN,avgP,avgN \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_mae,maxP,minN,avgP,avgN)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvaluating...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_file, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[24], line 12\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, device, loader, optimizer, criterion_fn, epoch, epochs)\u001B[0m\n\u001B[0;32m      9\u001B[0m avgN \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     11\u001B[0m pbar\u001B[38;5;241m=\u001B[39mtqdm(total \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(loader), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mit\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m:  \u001B[38;5;66;03m# 枚举所有批次的数据\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# print(step)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# print(type(batch))\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# 将数据移动到指定的设备\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# print(batch.x)\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mG:\\Anaconda\\envs\\py38\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # args=p_args()\n",
    "    args=MyNamespace()\n",
    "    main(args)\n",
    "    print('finish')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
