MyNamespace(batch_size=20, begin=0, checkpoint_path='./saves/GINGraph-con-v100_/checkpoint.pt', continue_train=False, data_type='smiles', dataset_pt='PTs/my_dataset.pt_0', dataset_split=[0.8, 0.19, 0.01], dataset_use_pt=True, device=device(type='cuda', index=0), drop_ratio=0.1, early_stop=30, early_stop_open=True, emb_dim=256, epochs=200, evaluate_epoch=3, graph_pooling='sum', learning_rate=0.0001, n_head=3, num_layers=3, num_tasks=1, num_workers=5, output_file=<_io.TextIOWrapper name='saves\\test_=1\\output' mode='a' encoding='cp936'>, root='./Dataset_Producer/Smiles_process/data.csv.gz', save_dir='saves\\test_=1', save_test=True, task_name='test', weight_decay=5e-06)
train data: 81 valid data: 19
#Params: 1237252
GINGraphPooling(
  (gnn_node): GINNodeEmbedding(
    (atom_encoder): EmbAtomEncoder(
      (atom_embedding_list): ModuleList(
        (0): Embedding(119, 256)
        (1): Embedding(4, 256)
        (2-3): 2 x Embedding(12, 256)
        (4): Embedding(10, 256)
        (5-6): 2 x Embedding(6, 256)
        (7-8): 2 x Embedding(2, 256)
      )
      (pos_encoder): PosEncoder()
    )
    (gnnconvs): ModuleList(
      (0-2): 3 x GINConv()
    )
    (attentionconvs): ModuleList(
      (0-2): 3 x MultiHeadAttention(
        (w_qs): Linear(in_features=256, out_features=255, bias=False)
        (w_ks): Linear(in_features=256, out_features=255, bias=False)
        (w_vs): Linear(in_features=256, out_features=255, bias=False)
        (fc): Linear(in_features=255, out_features=256, bias=False)
        (attention): ScaledDotProductAttention(
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (batch_norms): ModuleList(
      (0-2): 3 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=256, out_features=1, bias=True)
)
2023-07-30 00:24:43 =====Epoch 1
Training...
